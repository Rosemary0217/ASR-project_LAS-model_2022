{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn.utils as utils\n",
        "from torch.nn.functional import softmax\n",
        "from torch import bmm\n",
        "import random\n",
        "from matplotlib.lines import Line2D\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "GEMYn_X9IFbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDBPVbATfJnC",
        "outputId": "c97db851-bd4e-4c7f-f70f-ad11b2f13cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "os.system('mkdir ./data')\n",
        "os.system('mkdir ./checkpoint')\n",
        "os.system('mkdir ./attention')\n",
        "if not os.path.exists('./drive/MyDrive/datasets/11-785-s20-hw4p2.zip'):\n",
        "    print('zip doesn\\'t exist')\n",
        "else:\n",
        "    os.system('cp ./drive/MyDrive/datasets/11-785-s20-hw4p2.zip ./data/')\n",
        "    os.system('unzip ./data/11-785-s20-hw4p2.zip')\n",
        "    os.system('mv ./dev_new.npy ./data/')\n",
        "    os.system('mv ./dev_transcripts.npy ./data/')\n",
        "    os.system('mv ./test_new.npy ./data/')\n",
        "    os.system('mv ./test_sample_submission.csv ./data/')\n",
        "    os.system('mv ./train_new.npy ./data/')\n",
        "    os.system('mv ./train_transcripts.npy ./data/')"
      ],
      "metadata": {
        "id": "qonftjkWHUGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE"
      ],
      "metadata": {
        "id": "BBmhFAFcHWNk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9d013155-6ced-47a9-84a0-5f961f87c9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 数据预处理"
      ],
      "metadata": {
        "id": "p3FPmMrrHun0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 构建词典\n",
        "全局常量LETTER_LIST包含了输出序列中所有可能出现的字母与符号。create_dictionaries()函数返回两个字典letter2index和index2letter，前者可以通过符号索引它在LETTER_LIST中的位置，在数据预处理中会用到；后者与LETTER_LIST相同。"
      ],
      "metadata": {
        "id": "aEULo3vWbMsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LETTER_LIST = ['<pad>', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', \\\n",
        "               'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '-', \"'\", '.', '_', '+', ' ','<sos>','<eos>']"
      ],
      "metadata": {
        "id": "cNDBku8NHxiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Optional, create dictionaries for letter2index and index2letter transformations\n",
        "'''\n",
        "def create_dictionaries(letter_list):\n",
        "    length = len(letter_list)\n",
        "    letter2index = {letter_list[i]:i for i in range(length)}\n",
        "    index2letter = {i:letter_list[i] for i in range(length)}  # 深拷贝\n",
        "    return letter2index, index2letter\n",
        "\n",
        "letter2index, index2letter = create_dictionaries(LETTER_LIST)"
      ],
      "metadata": {
        "id": "UNjRk0P0KNV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 读取数据集\n",
        "load_data()函数用于从数据集中读取.npy文件并以np.array的格式返回。这个函数由[CMU 11-785 recitation](https://www.youtube.com/watch?v=02MjLlTuF3U&list=PLp-0K3kfddPwEwFEWePq10blIIneuP8ox&index=12)提供。"
      ],
      "metadata": {
        "id": "s1j-4dL1cMAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Loading all the numpy files containing the utterance information and text information\n",
        "'''\n",
        "def load_data(dataDir='./data/'):\n",
        "    speech_train = np.load(dataDir+\"train_new.npy\", allow_pickle=True, encoding='bytes')\n",
        "    speech_dev = np.load(dataDir+\"dev_new.npy\", allow_pickle=True, encoding='bytes')\n",
        "    speech_test = np.load(dataDir+\"test_new.npy\", allow_pickle=True, encoding='bytes')\n",
        "\n",
        "    transcript_train = np.load(dataDir+\"train_transcripts.npy\", allow_pickle=True, encoding='bytes')\n",
        "    transcript_dev = np.load(dataDir+\"dev_transcripts.npy\", allow_pickle=True, encoding='bytes')\n",
        "\n",
        "    return speech_train, transcript_train, speech_dev, transcript_dev, speech_test"
      ],
      "metadata": {
        "id": "Ip-uMl-JKRZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 调用load_data()，得到训练数据\n",
        "speech_train, transcript_train, speech_dev, transcript_dev, speech_test = load_data()"
      ],
      "metadata": {
        "id": "XXAyjjeANReo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们可以查看数据集大小及其中一条数据的内容："
      ],
      "metadata": {
        "id": "cowee8CXkB5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training set size:{}, {}'.format(speech_train.shape, transcript_train.shape))\n",
        "print('Development set size:{}, {}'.format(speech_dev.shape, transcript_dev.shape))\n",
        "print('Test set size:{}'.format(speech_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHLKZB7YMhgC",
        "outputId": "bda45fa2-8f48-44d8-e493-6576b6083b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size:(24724,), (24724,)\n",
            "Development set size:(1106,), (1106,)\n",
            "Test set size:(523,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speech_train[0], transcript_train[0]  # b stands for numpy.bytes_"
      ],
      "metadata": {
        "id": "KUvYGxUbZIz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13aab779-ef8b-499d-8e2a-a5b04ac2344a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-4.5242844, -5.708006 , -7.4425936, ..., -8.267208 , -3.5986276,\n",
              "         -8.46898  ],\n",
              "        [-4.960453 , -5.7416215, -7.937359 , ..., -8.147214 , -4.614257 ,\n",
              "         -7.7562113],\n",
              "        [-5.3406754, -5.157624 , -8.336189 , ..., -7.606736 , -5.0494947,\n",
              "         -7.9340124],\n",
              "        ...,\n",
              "        [-5.2470493, -5.99119  , -4.6648097, ..., -5.8244734, -3.8987803,\n",
              "         -5.8652916],\n",
              "        [-6.0679326, -5.1122055, -5.5143185, ..., -6.347003 , -4.585992 ,\n",
              "         -8.402996 ],\n",
              "        [-6.1676664, -5.1596828, -6.365869 , ..., -6.225582 , -4.6173177,\n",
              "         -7.6886425]], dtype=float32),\n",
              " array([b'THE', b'FEMALE', b'PRODUCES', b'A', b'LITTER', b'OF', b'TWO',\n",
              "        b'TO', b'FOUR', b'YOUNG', b'IN', b'NOVEMBER', b'AND', b'DECEMBER'],\n",
              "       dtype='|S8'))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 转换数据\n",
        "由于LETTER_LIST中\\<sos\\>、\\<eos\\>过长，为便于训练，使用transform_letter_to_index()函数将训练集和验证集中的文字转换为int类型的列表。"
      ],
      "metadata": {
        "id": "of-cLx9qLZZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_letter_to_index(transcript):\n",
        "    '''\n",
        "    :param transcript :(N, ) Transcripts are the text input\n",
        "    :param letter_list: Letter list defined above\n",
        "    :return letter_to_index_list: Returns a list for all the transcript sentence to index\n",
        "    '''\n",
        "    letter_to_index_list = []\n",
        "    for sentence in transcript:\n",
        "        idxs = [letter2index['<sos>']]\n",
        "        for word in sentence:\n",
        "            word_str = word.decode('utf-8')  # 从字节编码转换为string\n",
        "            for ch in word_str:\n",
        "                idxs.append(letter2index[ch])\n",
        "            idxs.append(letter2index[' ']) # 每两个词之间有空格\n",
        "        idxs.pop()\n",
        "        idxs.append(letter2index['<eos>']) # 处理完一个句子\n",
        "        letter_to_index_list.append(idxs)\n",
        "    return letter_to_index_list"
      ],
      "metadata": {
        "id": "5ngF97EZKVvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "由于训练的时候transcript使用数字表示，在输出的时候应该将其转化回字母和符号。使用transform_index_to_letter()函数实现了这一转换。"
      ],
      "metadata": {
        "id": "-K7DWMhed-qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_index_to_letter(index):\n",
        "    index_to_letter_list = []\n",
        "    for r in index:\n",
        "        letters = \"\"\n",
        "        for i in r:\n",
        "            if index2letter[i] == '<eos>' or index2letter[i] == '<pad>':\n",
        "                break\n",
        "            else:\n",
        "                letters += index2letter[i]\n",
        "        index_to_letter_list.append(letters)\n",
        "    return index_to_letter_list"
      ],
      "metadata": {
        "id": "QB6Qt3O_Kdpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "调用transform_letter_to_index()函数，将数据集转化成要输入的形式："
      ],
      "metadata": {
        "id": "X9kY4NncNi-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_train_idxs = transform_letter_to_index(transcript_train)\n",
        "text_dev_idxs = transform_letter_to_index(transcript_dev)"
      ],
      "metadata": {
        "id": "OZItPWAfNVtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 数据集类\n",
        "Speech2TextDataset类继承自torch.utils.data.Dataset类，通过重写\\_\\_getitem\\_\\_()方法，允许通过下标直接获得训练数据及其标签（如果有的话）。"
      ],
      "metadata": {
        "id": "5BTpjYzMewB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Speech2TextDataset(Dataset):\n",
        "    '''\n",
        "    Dataset class for the speech to text data, this may need some tweaking in the\n",
        "    getitem method as your implementation in the collate function may be different from\n",
        "    ours.\n",
        "    '''\n",
        "    def __init__(self, speech, text, isTrain=True):\n",
        "        self.dataX = speech\n",
        "        self.dataY = text\n",
        "        self.isTrain = isTrain\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataX.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.isTrain:  # 训练集包括数据和label\n",
        "            return torch.tensor(self.dataX[index].astype(np.float32)), torch.tensor(self.dataY[index])\n",
        "        else:  # 测试集只有数据，没有label\n",
        "            return torch.tensor(self.dataX[index].astype(np.float32))"
      ],
      "metadata": {
        "id": "QSGntqZkKf2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Speech2TextDataset(speech_train, text_train_idxs, isTrain=True)\n",
        "dev_dataset = Speech2TextDataset(speech_dev, text_dev_idxs, isTrain=True)\n",
        "test_dataset = Speech2TextDataset(speech_test, text=None, isTrain=False)"
      ],
      "metadata": {
        "id": "Tyadm8KpNYTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 数据对齐"
      ],
      "metadata": {
        "id": "RI1fENWkfWa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_train(batch):\n",
        "    ### Return the padded speech and text data, and the length of utterance and transcript ###\n",
        "    padded_inputs, input_lens = [], []\n",
        "    padded_targets, target_lens = [], []\n",
        "    l = len(batch)\n",
        "    for i in range(l):\n",
        "        padded_inputs.append(torch.tensor(batch[i][0]))\n",
        "        padded_targets.append(torch.tensor(batch[i][1][1:])) # 不取<sos>\n",
        "        input_lens.append(len(batch[i][0]))\n",
        "        target_lens.append(len(batch[i][1])-1) #  sentence <eos>\n",
        "    padded_inputs = pad_sequence(padded_inputs, batch_first=True) # dim (B, T, C) since batch_first is true, (T, B, C) if false\n",
        "    padded_targets = pad_sequence(padded_targets, batch_first=True)\n",
        "    return padded_inputs, padded_targets, torch.tensor(input_lens), torch.tensor(target_lens)\n",
        "\n",
        "def collate_test(batch):\n",
        "    ### Return padded speech and length of utterance ###\n",
        "    padded_inputs, input_lens = [], []\n",
        "    l = len(batch)\n",
        "    for b in range(l):\n",
        "        padded_inputs.append(torch.tensor(batch[b]))\n",
        "        input_lens.append(len(batch[b]))\n",
        "    padded_inputs = pad_sequence(padded_inputs, batch_first=True)\n",
        "    return padded_inputs, torch.tensor(input_lens)"
      ],
      "metadata": {
        "id": "T70qEK-LKmMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 获取DataLoader\n",
        "torch.nn.data.DataLoader类返回数据迭代器。参数collate_fn将一系列样本合并并返回小批量tensor。"
      ],
      "metadata": {
        "id": "S5XWMyWKlpec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64 if DEVICE=='cuda' else 1\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_train) # 训练集，387个batch\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_train) # 验证集，18个batch\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_test) # 测试集，9个batch"
      ],
      "metadata": {
        "id": "hEVbevlQlxkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 模型\n",
        "模型由五个类组成，分别是Attention，Encoder，Decoder，PBLSTM, LAS，其中LAS为包装类。部分代码框架由recitation给出，实现过程中保留了相关英文注释。"
      ],
      "metadata": {
        "id": "VrbUEje8H1_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "注意力机制"
      ],
      "metadata": {
        "id": "YQQ4m056QZ8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    '''\n",
        "    Attention is calculated using key, value and query from Encoder and decoder.\n",
        "    Below are the set of operations you need to perform for computing attention:\n",
        "        energy = bmm(key, query)\n",
        "        attention = softmax(energy)\n",
        "        context = bmm(attention, value)\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def forward(self, query, key, value, lens):\n",
        "        '''\n",
        "        :param query :(N, context_size) Query is the output of LSTMCell from Decoder\n",
        "        :param key: (N, T_max, key_size) Key Projection from Encoder per time step\n",
        "        :param value: (N, T_max, value_size) Value Projection from Encoder per time step\n",
        "        :param lens: (N, T) Length of key and value, used for binary masking\n",
        "        :return output: Attended Context\n",
        "        :return attention: Attention mask that can be plotted\n",
        "        '''\n",
        "        # binary masking for padded positions\n",
        "        mask = torch.arange(key.size(1)).unsqueeze(0) >= lens.unsqueeze(1) # (1, T_max) >= (B, 1) -> (N, T_max)\n",
        "        mask = mask.to(DEVICE)\n",
        "\n",
        "        # print(\"key_size:{}\".format(key.size()))  # torch.Size([64, 256, 128])\n",
        "        # print(\"query_size:{}\".format(query.size()))  # torch.Size([64, 128])\n",
        "        # batch matrix multiplication\n",
        "        energy = bmm(key, query.unsqueeze(2)) # (batch, T_max, key_size) * (batch, context_size, 1) = (batch, T_max, 1)\n",
        "        energy = energy.squeeze(2)  # (N, T_max)\n",
        "        # print('energy_size:{}'.format(energy.size()))  # torch.Size([64, 256])\n",
        "        energy.masked_fill_(mask, -1e9) # (N, T_max)\n",
        "        attention = softmax(energy, dim=1) # (N, T_max)\n",
        "        # print('attention_size:{}'.format(attention.size()))    # torch.Size([64, 256])\n",
        "        context = bmm(attention.unsqueeze(1), value).squeeze(1) # (N, T_max)\n",
        "\n",
        "        return context, attention"
      ],
      "metadata": {
        "id": "raCRp7NoH1vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pBLSTM结构是模型Encoder部分的核心。它的物理结构是一个单层的双向LSTM网络，但是在前向传播的过程中，每层网络将输入维度减半而维度不总是偶数，因此需要去除多余的序列。"
      ],
      "metadata": {
        "id": "mVeSTIKLVNJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class pBLSTM(nn.Module):\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(pBLSTM, self).__init__()\n",
        "        self.blstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        :param x :(N, T) input to the pBLSTM\n",
        "        :return output: (N, T, H) encoded sequence from pyramidal Bi-LSTM\n",
        "        '''\n",
        "        x_padded, x_lens = pad_packed_sequence(x, batch_first=True)\n",
        "        x_padded = x_padded[:, :(x_padded.size(1)//2)*2, :] # (B, T, dim); 长度不一定是2的倍数\n",
        "        x_reshaped = x_padded.reshape(x_padded.size(0), x_padded.size(1)//2, x_padded.size(2)*2) # reshape to (B, T/2, dim*2),长度减半\n",
        "        x_packed = pack_padded_sequence(x_reshaped, lengths=(x_lens//2).cpu(), batch_first=True, enforce_sorted=False)  # （B, T/2, input_dim）\n",
        "        output, _ = self.blstm(x_packed)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "ALnt4OxPMUD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "编码器接收语料为输入，输出key-value对，它们就是对pBLSTM网络输出的简单映射。"
      ],
      "metadata": {
        "id": "y09MA-SmQ0MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    Encoder takes the utterances as inputs and returns the key and value.\n",
        "    Key and value are nothing but simple projections of the output from pBLSTM network.\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim, value_size=128, key_size=128):\n",
        "        super(Encoder, self).__init__()\n",
        "        # 底层LSTM\n",
        "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "        ### Add code to define the blocks of pBLSTMs! ###\n",
        "        # 3层pBLSTM\n",
        "        self.pBLSTMs = nn.Sequential(\n",
        "            pBLSTM(hidden_dim*4, hidden_dim),\n",
        "            pBLSTM(hidden_dim*4, hidden_dim),\n",
        "            pBLSTM(hidden_dim*4, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.key_network = nn.Linear(hidden_dim*2, value_size)\n",
        "        self.value_network = nn.Linear(hidden_dim*2, key_size)\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        rnn_inp = pack_padded_sequence(x, lengths=lens.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        outputs, _ = self.lstm(rnn_inp)\n",
        "\n",
        "        ### Use the outputs and pass it through the pBLSTM blocks! ###\n",
        "        outputs = self.pBLSTMs(outputs)\n",
        "\n",
        "        linear_input, encoder_lens = pad_packed_sequence(outputs, batch_first=True)\n",
        "        keys = self.key_network(linear_input)\n",
        "        value = self.value_network(linear_input)\n",
        "        return keys, value, encoder_lens"
      ],
      "metadata": {
        "id": "DJJPFZpXMbs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "解码器(Speller)对输入序列进行预测。"
      ],
      "metadata": {
        "id": "gWb2vZEFjg8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step,\n",
        "    thus we use LSTMCell instead of LSLTM here.\n",
        "    The output from the second LSTMCell can be used as query here for attention module.\n",
        "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
        "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
        "    '''\n",
        "    def __init__(self, vocab_size, decoder_hidden_dim, embed_dim, value_size=128, key_size=128, isAttended=False):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm1 = nn.LSTMCell(input_size=embed_dim+value_size, hidden_size=decoder_hidden_dim)\n",
        "        self.lstm2 = nn.LSTMCell(input_size=decoder_hidden_dim, hidden_size=key_size)\n",
        "        self.character_prob = nn.Linear(key_size+value_size, vocab_size)\n",
        "        self.value_size = value_size\n",
        "        self.hidden_dim = decoder_hidden_dim\n",
        "\n",
        "        self.isAttended = isAttended\n",
        "        if self.isAttended:\n",
        "            self.attention = Attention()\n",
        "\n",
        "    def forward(self, key, values, encoder_lens, epoch, batch_idx, text=None, isTrain=True):\n",
        "        '''\n",
        "        :param key :(N, T, key_size) Output of the Encoder Key projection layer\n",
        "        :param values: (N, T, value_size) Output of the Encoder Value projection layer\n",
        "        :param text: (N, text_len) Batch input of text with text_length\n",
        "        :param isTrain: Train or eval mode\n",
        "        :return predictions: Returns the character perdiction probability\n",
        "        '''\n",
        "        batch_size = key.shape[0]\n",
        "\n",
        "        # 超参\n",
        "        teacherForcingRate = 0.1\n",
        "        isGumbel=True\n",
        "\n",
        "        if isTrain:\n",
        "            embeddings = self.embedding(text)\n",
        "            max_len =  text.shape[1]\n",
        "        else:\n",
        "            max_len = 250\n",
        "\n",
        "        predictions = []\n",
        "        hidden_states = [None, None]\n",
        "        prediction = torch.zeros(batch_size, 1).to(DEVICE)\n",
        "\n",
        "        context = values[:, 0, :]  # initialize context\n",
        "        attention_plot_list = []\n",
        "        for i in range(max_len):\n",
        "            # * Implement Gumble noise and teacher forcing techniques\n",
        "            # * When attention is True, replace values[i,:,:] with the context you get from attention.\n",
        "            # * If you haven't implemented attention yet, then you may want to check the index and break\n",
        "            #   out of the loop so you do you do not get index out of range errors.\n",
        "\n",
        "            if isTrain: # 训练模式\n",
        "                # 首先决定是否使用teacher forcing technique\n",
        "                rand = random.random()\n",
        "                if rand <= teacherForcingRate:\n",
        "                  isTF = True\n",
        "                else:\n",
        "                  isTF = False\n",
        "\n",
        "                if isTF:  # 使用teacher forcing, 前一步的输出作为下一步的输入\n",
        "                    if i != 0 and isGumbel:   # 添加gumbel noise，增强多样性\n",
        "                        char_embed = torch.nn.functional.gumbel_softmax(prediction).mm(self.embedding.weight)\n",
        "                    else:\n",
        "                        char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "                else:  # 不用teacher forcing, ground truth作为输入\n",
        "                    if i == 0:\n",
        "                        start_input = torch.zeros(batch_size, dtype=torch.long).fill_(letter2index['<sos>']).to(DEVICE)\n",
        "                        char_embed = self.embedding(start_input)\n",
        "                    else:\n",
        "                        char_embed = embeddings[:, i-1, :]\n",
        "            else:  # 测试或验证模式\n",
        "                if i == 0:  # 开始：以<sos>作为输入\n",
        "                    start_input = torch.zeros(batch_size, dtype=torch.long).fill_(letter2index['<sos>']).to(DEVICE)\n",
        "                    char_embed = self.embedding(start_input)\n",
        "                else:\n",
        "                    char_embed = self.embedding(prediction.argmax(dim=-1))  # 概率最高的char作为输出\n",
        "\n",
        "            # decoder的输入是将char_embed与context拼接\n",
        "            input1 = torch.cat([char_embed, context], dim=1)\n",
        "            hidden_states[0] = self.lstm1(input1, hidden_states[0])\n",
        "            # print('hidden_states.shape:{}'.format(hidden_states[0].shape))\n",
        "            input2 = hidden_states[0][0]\n",
        "            hidden_states[1] = self.lstm2(input2, hidden_states[1]) # output (h_1, c_1)\n",
        "\n",
        "            ### Compute attention from the output of the second LSTM Cell ###\n",
        "            output = hidden_states[1][0]\n",
        "\n",
        "            # 计算attention\n",
        "            if self.isAttended:\n",
        "                context, attention = self.attention(output, key, values, encoder_lens)  # 均为(batch_size, T_max)\n",
        "                if batch_idx % 64 == 0 and isTrain:\n",
        "                    cur_attention = attention[0].detach().cpu()\n",
        "                    attention_plot_list.append(cur_attention)\n",
        "            else:\n",
        "                if i < values.size(1):\n",
        "                    context = values[:, i, :]\n",
        "                else:\n",
        "                    context = torch.zeros(batch_size, self.value_size).to(DEVICE)\n",
        "            # 预测\n",
        "            prob_input = torch.cat([output, context],dim=1)\n",
        "            prediction = self.character_prob(prob_input)\n",
        "            predictions.append(prediction.unsqueeze(1))\n",
        "\n",
        "        # Plot attention plot\n",
        "        if batch_idx % 64 == 0 and isTrain:\n",
        "            attentions = torch.stack(attention_plot_list, dim=1)\n",
        "            plt.clf()\n",
        "            sns.heatmap(attentions, cmap='Reds')  # heatmap并保存\n",
        "            plt.savefig(\"./attention/heatE{}B{}.png\".format(epoch,batch_idx))\n",
        "\n",
        "        return torch.cat(predictions, dim=1)"
      ],
      "metadata": {
        "id": "JXrN5ZmqMyqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "最后使用LAS类对编码器和解码器进行包装。"
      ],
      "metadata": {
        "id": "tFvLABGKjm2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LAS(nn.Module):\n",
        "    '''\n",
        "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
        "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
        "    '''\n",
        "    def __init__(self, input_dim, vocab_size, encoder_hidden_dim=256, decoder_hidden_dim=512, embed_dim=256, value_size=128, key_size=128, isAttended=False):\n",
        "        super(LAS, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, encoder_hidden_dim)\n",
        "        self.decoder = Decoder(vocab_size, decoder_hidden_dim, embed_dim, value_size, key_size, isAttended)\n",
        "\n",
        "    def forward(self, speech_input, speech_len, epoch, batchNum, text_input=None, isTrain=True):\n",
        "        key, value, encoder_lens = self.encoder(speech_input, speech_len)\n",
        "        if isTrain:   # 训练模式需要传入label\n",
        "            predictions = self.decoder(key, value, encoder_lens, epoch, batchNum, text_input, isTrain=True)\n",
        "        else:\n",
        "            predictions = self.decoder(key, value, encoder_lens, epoch, batchNum, text=None, isTrain=False)\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "Nqk89mTCM2ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 训练"
      ],
      "metadata": {
        "id": "LXqN781eIXiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 掩码\n",
        "由于在数据预处理阶段对音频进行了对齐处理，在计算损失时应该把这部分排除在外，掩码和pytorch的广播机制为实现提供了可能。"
      ],
      "metadata": {
        "id": "9sqWlaVFfxMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mask(lens):\n",
        "    # print('lens_size:{}'.format(lens.size()))  # N\n",
        "    lens = torch.tensor(lens).to(DEVICE)  # N\n",
        "    max_len = torch.max(lens)\n",
        "    mask = (torch.arange(0, max_len).repeat(lens.size(0), 1).to(DEVICE) < lens.unsqueeze(1).expand(lens.size(0), max_len)).int()\n",
        "    # print('generated_mask_size:{}'.format(mask.size()))  # torch.Size([64, 201]) in 1 training\n",
        "    return mask"
      ],
      "metadata": {
        "id": "fQGHGHzxQK0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 验证函数"
      ],
      "metadata": {
        "id": "9EGpKEmXf4Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_edit_dist(preds, targets):\n",
        "    dist = 0.0\n",
        "    for pred, target in zip(preds, targets):\n",
        "        dist += torchaudio.functional.edit_distance(pred, target)\n",
        "    return dist"
      ],
      "metadata": {
        "id": "xGTDbmqNJ9NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, test_loader, criterion, epoch):\n",
        "    ### Write your test code here! ###\n",
        "    model.eval()\n",
        "    model.to(DEVICE)\n",
        "    LevDist, num_seq = 0.0, 0.0\n",
        "    for batch_idx, (data, target, dataLens, targetLens) in enumerate(test_loader):\n",
        "        data, target, dataLens, targetLens = data.to(DEVICE), target.to(DEVICE), dataLens.to(DEVICE), targetLens.to(DEVICE)\n",
        "        predictions = model(data, dataLens, epoch, batch_idx, text_input=None, isTrain=False)\n",
        "\n",
        "        # Compare validation edit distance\n",
        "        pred = transform_index_to_letter(predictions.argmax(-1).detach().cpu().numpy())\n",
        "        target = transform_index_to_letter(target.detach().cpu().numpy())\n",
        "\n",
        "        LevDist += calc_edit_dist(pred, target)\n",
        "        # val_loss_list.append(LevDist)\n",
        "        num_seq += len(pred)\n",
        "\n",
        "        del data\n",
        "        del target\n",
        "        del dataLens\n",
        "        del targetLens\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return LevDist/num_seq, LevDist"
      ],
      "metadata": {
        "id": "o8spVYrAQeg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 超参数"
      ],
      "metadata": {
        "id": "CNy1WrIXjgG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 30\n",
        "ENCODER_HIDDEN_DIM = 256\n",
        "DECODER_HIDDEN_DIM = 512\n",
        "EMBED_DIM = 256\n",
        "VALUE_SIZE = 128\n",
        "KEY_SIZE = 128\n",
        "IS_ATTENDED = True\n",
        "PRETRAINED = True  # 分多次训练或演示时置为True\n",
        "CHECKPOINT_DIR = \"./drive/MyDrive/checkpoints/\"\n",
        "SAVED_CHECKPOINT = \"./drive/MyDrive/checkpoint/init_model29.txt\"\n",
        "SAVED_SCHEDULER = \"./drive/MyDrive/checkpoint/init_scheduler29.txt\"\n",
        "TEST_PRED_CSV_PATH = './data/predicted_test.csv'\n",
        "DEV_PRED_CSV_PATH = './data/predicted_dev.csv'\n",
        "TEST_PRED_NPY_PATH = './data/predicted_test.npy'"
      ],
      "metadata": {
        "id": "ms0nbtDEKE9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 定义模型、优化器、学习率调节器\n",
        "使用LAS类对象作为模型，Adam作为优化器，ReduceLROnPlateau算法调节学习率。由于训练时直接使用edit distance作为损失函数会导致计算量大幅增加，且预测可以近似为每一个位置进行40分类问题，因此使用CE loss作为训练时的损失函数。"
      ],
      "metadata": {
        "id": "tCqgUCfJklyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LAS(input_dim=40, vocab_size=len(LETTER_LIST), encoder_hidden_dim=ENCODER_HIDDEN_DIM,\n",
        "                decoder_hidden_dim=DECODER_HIDDEN_DIM,\n",
        "                embed_dim=EMBED_DIM,\n",
        "                value_size=VALUE_SIZE,\n",
        "                key_size=KEY_SIZE,\n",
        "                isAttended=IS_ATTENDED)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# criterion = calc_edit_dist\n",
        "criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.80, patience=1, verbose=True, threshold=1e-2)"
      ],
      "metadata": {
        "id": "6x2GGstSNbh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "若模型已经训练了一部分，恢复上次的参数："
      ],
      "metadata": {
        "id": "bGhMJRR7kzcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PRETRAINED:\n",
        "      checkpoint = torch.load(SAVED_CHECKPOINT)\n",
        "      model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "      model.to(DEVICE)\n",
        "      optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "      checkpoint = torch.load(SAVED_SCHEDULER)\n",
        "      scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
        "\n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "id": "pzMmejw6NmJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3ef795-e830-4b24-8182-1c47a819da11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LAS(\n",
              "  (encoder): Encoder(\n",
              "    (lstm): LSTM(40, 256, batch_first=True, bidirectional=True)\n",
              "    (pBLSTMs): Sequential(\n",
              "      (0): pBLSTM(\n",
              "        (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      )\n",
              "      (1): pBLSTM(\n",
              "        (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      )\n",
              "      (2): pBLSTM(\n",
              "        (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      )\n",
              "    )\n",
              "    (key_network): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (value_network): Linear(in_features=512, out_features=128, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(35, 256, padding_idx=0)\n",
              "    (lstm1): LSTMCell(384, 512)\n",
              "    (lstm2): LSTMCell(512, 128)\n",
              "    (character_prob): Linear(in_features=256, out_features=35, bias=True)\n",
              "    (attention): Attention()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 训练函数"
      ],
      "metadata": {
        "id": "0LwKVaN9k6_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, epoch):\n",
        "      # training mode\n",
        "      model.train()\n",
        "      model.to(DEVICE)\n",
        "      trainingLoss, trainingPerplex = 0.0, 0.0\n",
        "      # 1) Iterate through your loader\n",
        "      for batch_idx, (data, target, dataLens, targetLens) in enumerate(train_loader):\n",
        "          # 2) Use torch.autograd.set_detect_anomaly(True) to get notices about gradient explosion\n",
        "          with torch.autograd.set_detect_anomaly(False):\n",
        "              # 3) Set the inputs to the device.\n",
        "              data, target, dataLens, targetLens = data.to(DEVICE), target.to(DEVICE), dataLens.to(DEVICE), targetLens.to(DEVICE)\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # 4) Pass your inputs, and length of speech into the model.\n",
        "              predictions = model(speech_input=data, speech_len=dataLens, epoch=epoch, batchNum=batch_idx, text_input=target, isTrain=True)\n",
        "\n",
        "              # 5) Generate a mask based on the lengths of the text to create a masked loss.\n",
        "              # 5.1) Ensure the mask is on the device and is the correct shape.\n",
        "              mask = generate_mask(targetLens).to(DEVICE)\n",
        "\n",
        "              # print('batch no.:{}'.format(batch_idx))\n",
        "              # 7) Use the criterion to get the loss.\n",
        "              loss = criterion(predictions.view(-1, predictions.size(2)), target.view(-1))\n",
        "              # print('loss_size:{}'.format(loss.size()))\n",
        "              # print(mask.size())\n",
        "              # print(mask[3])\n",
        "              # print(torch.sum(mask.view(-1)))\n",
        "              # 8) Use the mask to calculate a masked loss.\n",
        "              masked_loss = torch.sum(loss * mask.view(-1)) / torch.sum(mask) # 将mask flatten以计算内积\n",
        "              # masked_loss = loss.sum() / targetLens.sum()\n",
        "\n",
        "              ## Cumulate running loss and perplexity ##\n",
        "              currLoss = masked_loss.item()\n",
        "              currPerplex = torch.exp(masked_loss).item()\n",
        "              trainingLoss += currLoss\n",
        "              trainingPerplex += currPerplex\n",
        "\n",
        "              # 9) Run the backward pass on the masked loss.\n",
        "              masked_loss.backward()\n",
        "              # 10) Use torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
        "              torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
        "              # 11) Take a step with your optimizer\n",
        "              optimizer.step()\n",
        "\n",
        "              del data\n",
        "              del target\n",
        "              del dataLens\n",
        "              del targetLens\n",
        "              torch.cuda.empty_cache()\n",
        "\n",
        "      return trainingLoss/len(train_loader), trainingPerplex/len(train_loader)"
      ],
      "metadata": {
        "id": "5rWiooXiWlOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, epoch):\n",
        "      # training mode\n",
        "      model.train()\n",
        "      model.to(DEVICE)\n",
        "      trainingLoss, trainingPerplex = 0.0, 0.0\n",
        "      # 1) Iterate through your loader\n",
        "      for batch_idx, (data, target, dataLens, targetLens) in enumerate(train_loader):\n",
        "          # 2) Use torch.autograd.set_detect_anomaly(True) to get notices about gradient explosion\n",
        "          with torch.autograd.set_detect_anomaly(False):\n",
        "              # 3) Set the inputs to the device.\n",
        "              data, target, dataLens, targetLens = data.to(DEVICE), target.to(DEVICE), dataLens.to(DEVICE), targetLens.to(DEVICE)\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # 4) Pass your inputs, and length of speech into the model.\n",
        "              predictions = model(speech_input=data, speech_len=dataLens, epoch=epoch, batchNum=batch_idx, text_input=target, isTrain=True)\n",
        "\n",
        "              # 5) Generate a mask based on the lengths of the text to create a masked loss.\n",
        "              # 5.1) Ensure the mask is on the device and is the correct shape.\n",
        "              mask = generate_mask(targetLens).to(DEVICE)\n",
        "\n",
        "              # 7) Use the criterion to get the loss.\n",
        "              loss = criterion(predictions.view(-1, predictions.size(2)), target.view(-1))\n",
        "\n",
        "              # 8) Use the mask to calculate a masked loss.\n",
        "              masked_loss = torch.sum(loss * mask.view(-1)) / torch.sum(mask) # 将mask flatten以计算内积\n",
        "              ## Cumulate running loss and perplexity ##\n",
        "              currLoss = masked_loss.item()\n",
        "              currPerplex = torch.exp(masked_loss).item()\n",
        "              trainingLoss += currLoss\n",
        "              trainingPerplex += currPerplex\n",
        "\n",
        "              # 9) Run the backward pass on the masked loss.\n",
        "              masked_loss.backward()\n",
        "              # 10) Use torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
        "              torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
        "              # 11) Take a step with your optimizer\n",
        "              optimizer.step()\n",
        "\n",
        "              del data\n",
        "              del target\n",
        "              del dataLens\n",
        "              del targetLens\n",
        "              torch.cuda.empty_cache()\n",
        "\n",
        "      return trainingLoss/len(train_loader), trainingPerplex/len(train_loader)"
      ],
      "metadata": {
        "id": "tPRX2lvDuHUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "train_loss_list = []\n",
        "train_perplex_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "      loss, perp = train(model, train_loader, criterion, optimizer, epoch)\n",
        "      train_loss_list.append(loss)\n",
        "      train_perplex_list.append(perp)\n",
        "\n",
        "      # Save checkpoint\n",
        "      path = \"./drive/MyDrive/checkpoint/init_model{}.txt\".format(epoch)\n",
        "      torch.save({'epoch':epoch, 'model_state_dict':model.state_dict(), 'optimizer_state_dict':optimizer.state_dict()}, path)\n",
        "\n",
        "      # Evaluate\n",
        "      avgEditDist, _ = eval_model(model, dev_loader, criterion, epoch)\n",
        "      val_loss_list.append(avgEditDist)\n",
        "      scheduler.step(avgEditDist)\n",
        "      torch.save({'epoch':epoch, 'scheduler_state_dict':scheduler.state_dict()}, \"./drive/MyDrive/checkpoint/init_scheduler{}.txt\".format(epoch))\n",
        "\n",
        "      print('In epoch {},\\t train_loss:{:.5f}\\t train_perplexity:{:.5f}\\t'.format(epoch, loss, perp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "RYKXzp0oiAzS",
        "outputId": "35964ddc-f720-4fe1-f4b9-c92cb8dd8af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0,\t train_loss:1.91992\t train_perplexity:7.38317\t\n",
            "In epoch 1,\t train_loss:1.46708\t train_perplexity:4.35159\t\n",
            "Epoch 00003: reducing learning rate of group 0 to 8.0000e-04.\n",
            "In epoch 2,\t train_loss:1.34399\t train_perplexity:3.84584\t\n",
            "In epoch 3,\t train_loss:1.24790\t train_perplexity:3.49374\t\n",
            "In epoch 4,\t train_loss:1.19581\t train_perplexity:3.31590\t\n",
            "Epoch 00006: reducing learning rate of group 0 to 6.4000e-04.\n",
            "In epoch 5,\t train_loss:1.16169\t train_perplexity:3.20591\t\n",
            "In epoch 6,\t train_loss:1.11553\t train_perplexity:3.06004\t\n",
            "In epoch 7,\t train_loss:1.09693\t train_perplexity:3.00367\t\n",
            "In epoch 8,\t train_loss:1.07450\t train_perplexity:2.93757\t\n",
            "In epoch 9,\t train_loss:1.05214\t train_perplexity:2.87201\t\n",
            "Epoch 00011: reducing learning rate of group 0 to 5.1200e-04.\n",
            "In epoch 10,\t train_loss:1.02101\t train_perplexity:2.78409\t\n",
            "In epoch 11,\t train_loss:0.94211\t train_perplexity:2.57175\t\n",
            "In epoch 12,\t train_loss:0.77783\t train_perplexity:2.18450\t\n",
            "In epoch 13,\t train_loss:0.56897\t train_perplexity:1.77065\t\n",
            "In epoch 14,\t train_loss:0.43240\t train_perplexity:1.54282\t\n",
            "In epoch 15,\t train_loss:0.35172\t train_perplexity:1.42261\t\n",
            "In epoch 16,\t train_loss:0.30993\t train_perplexity:1.36416\t\n",
            "In epoch 17,\t train_loss:0.27798\t train_perplexity:1.32122\t\n",
            "In epoch 18,\t train_loss:0.25170\t train_perplexity:1.28684\t\n",
            "In epoch 19,\t train_loss:0.22443\t train_perplexity:1.25211\t\n",
            "In epoch 20,\t train_loss:0.21211\t train_perplexity:1.23685\t\n",
            "In epoch 21,\t train_loss:0.19747\t train_perplexity:1.21883\t\n",
            "In epoch 22,\t train_loss:0.18185\t train_perplexity:1.19998\t\n",
            "In epoch 23,\t train_loss:0.17693\t train_perplexity:1.19400\t\n",
            "In epoch 24,\t train_loss:0.15824\t train_perplexity:1.17184\t\n",
            "Epoch 00026: reducing learning rate of group 0 to 4.0960e-04.\n",
            "In epoch 25,\t train_loss:0.17329\t train_perplexity:1.18986\t\n",
            "In epoch 26,\t train_loss:0.14675\t train_perplexity:1.15838\t\n",
            "In epoch 27,\t train_loss:0.13660\t train_perplexity:1.14668\t\n",
            "Epoch 00029: reducing learning rate of group 0 to 3.2768e-04.\n",
            "In epoch 28,\t train_loss:0.12292\t train_perplexity:1.13110\t\n",
            "In epoch 29,\t train_loss:0.10458\t train_perplexity:1.11046\t\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "train_loss_list = []\n",
        "train_perplex_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "      loss, perp = train(model, train_loader, criterion, optimizer, epoch)\n",
        "      train_loss_list.append(loss)\n",
        "      train_perplex_list.append(perp)\n",
        "\n",
        "      # Save checkpoint\n",
        "      path = \"./drive/MyDrive/init_epoch{}.txt\".format(epoch)\n",
        "      torch.save({'epoch':epoch, 'model_state_dict':model.state_dict(), 'optimizer_state_dict':optimizer.state_dict()}, path)\n",
        "\n",
        "      # Evaluate\n",
        "      avgEditDist, _ = eval_model(model, dev_loader, criterion, epoch)\n",
        "      val_loss_list.append(avgEditDist)\n",
        "      scheduler.step(avgEditDist)\n",
        "      torch.save({'epoch':epoch, 'scheduler_state_dict':scheduler.state_dict()}, \"./drive/MyDrive/init_scheduler{}.txt\".format(epoch))\n",
        "\n",
        "      print('In epoch {},\\t train_loss:{:.5f}\\t train_perplexity:{:.5f}\\t'.format(epoch, loss, perp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSEYYig65cf9",
        "outputId": "6e1eb1c7-9f72-4568-c536-23fb8f8b1281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0,\t train_loss:1.93423\t train_perplexity:7.47307\t\n",
            "Epoch 00027: reducing learning rate of group 0 to 7.5000e-04.\n",
            "In epoch 1,\t train_loss:1.46864\t train_perplexity:4.36268\t\n",
            "In epoch 2,\t train_loss:1.31018\t train_perplexity:3.71919\t\n",
            "Epoch 00029: reducing learning rate of group 0 to 5.6250e-04.\n",
            "In epoch 3,\t train_loss:1.23518\t train_perplexity:3.44986\t\n",
            "In epoch 4,\t train_loss:1.17447\t train_perplexity:3.24761\t\n",
            "Epoch 00031: reducing learning rate of group 0 to 4.2188e-04.\n",
            "In epoch 5,\t train_loss:1.12685\t train_perplexity:3.09560\t\n",
            "In epoch 6,\t train_loss:1.02802\t train_perplexity:2.80638\t\n",
            "Epoch 00033: reducing learning rate of group 0 to 3.1641e-04.\n",
            "In epoch 7,\t train_loss:0.69870\t train_perplexity:2.02823\t\n",
            "In epoch 8,\t train_loss:0.41548\t train_perplexity:1.51722\t\n",
            "Epoch 00035: reducing learning rate of group 0 to 2.3730e-04.\n",
            "In epoch 9,\t train_loss:0.30824\t train_perplexity:1.36201\t\n",
            "In epoch 10,\t train_loss:0.23456\t train_perplexity:1.26483\t\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.7798e-04.\n",
            "In epoch 11,\t train_loss:0.19726\t train_perplexity:1.21848\t\n",
            "In epoch 12,\t train_loss:0.16165\t train_perplexity:1.17577\t\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.3348e-04.\n",
            "In epoch 13,\t train_loss:0.13966\t train_perplexity:1.15010\t\n",
            "In epoch 14,\t train_loss:0.11591\t train_perplexity:1.12308\t\n",
            "Epoch 00041: reducing learning rate of group 0 to 1.0011e-04.\n",
            "In epoch 15,\t train_loss:0.10242\t train_perplexity:1.10802\t\n",
            "In epoch 16,\t train_loss:0.08623\t train_perplexity:1.09021\t\n",
            "Epoch 00043: reducing learning rate of group 0 to 7.5085e-05.\n",
            "In epoch 17,\t train_loss:0.07675\t train_perplexity:1.07990\t\n",
            "In epoch 18,\t train_loss:0.06529\t train_perplexity:1.06756\t\n",
            "Epoch 00045: reducing learning rate of group 0 to 5.6314e-05.\n",
            "In epoch 19,\t train_loss:0.05881\t train_perplexity:1.06067\t\n",
            "In epoch 20,\t train_loss:0.05087\t train_perplexity:1.05227\t\n",
            "Epoch 00047: reducing learning rate of group 0 to 4.2235e-05.\n",
            "In epoch 21,\t train_loss:0.04670\t train_perplexity:1.04788\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "#逐个添加文件打包，未打包空子目录。可过滤文件。\n",
        "#如果只打包不压缩，将\"w:gz\"参数改为\"w:\"或\"w\"即可。\n",
        "def make_targz_one_by_one(output_filename, source_dir):\n",
        "    tar = tarfile.open(output_filename,\"w:gz\")\n",
        "    for root,dir_name,files_list in os.walk(source_dir):\n",
        "      for file in files_list:\n",
        "        pathfile = os.path.join(root, file)\n",
        "        tar.add(pathfile)\n",
        "    tar.close()\n",
        "    os.system('mv attention3.zip drive/MyDrive/')\n",
        "\n",
        "make_targz_one_by_one('attention3.zip', './attention/')"
      ],
      "metadata": {
        "id": "C6MXryGkDk7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 推断（预测）"
      ],
      "metadata": {
        "id": "cU2PSBJElBVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, data_loader, csv_path, isValid=False):\n",
        "    model.eval()\n",
        "    model.to(DEVICE)\n",
        "    res = []\n",
        "    with torch.no_grad():\n",
        "        if isValid:  # validation mode\n",
        "            targetRes = []\n",
        "            totalDist, num_seq = 0.0, 0.0\n",
        "            for batch_idx, (data, target, dataLens, targetLens) in enumerate(data_loader):\n",
        "                data, target, dataLens, targetLens = data.to(DEVICE), target.to(DEVICE), dataLens.to(DEVICE), targetLens.to(DEVICE)\n",
        "                predictions = model(data, dataLens, 30, batch_idx, text_input=None, isTrain=False)\n",
        "\n",
        "                # 计算edit dist\n",
        "                predText = transform_index_to_letter(predictions.argmax(-1).detach().cpu().numpy())  #使用最大prob的下标查表\n",
        "                targetText = transform_index_to_letter(target.detach().cpu().numpy())\n",
        "                totalDist += calc_edit_dist(predText, targetText)\n",
        "                num_seq += len(predText)\n",
        "\n",
        "                # 使用entend向list末尾追加多个元素\n",
        "                # 不能用append，否则res的长度只会和batch的数量一样\n",
        "                res.extend(predText)\n",
        "                targetRes.extend(targetText)\n",
        "\n",
        "            print(\"Average edit distance on validation set:\\t{:.5f}\".format(totalDist/num_seq))\n",
        "            # print(num_seq)\n",
        "            df = pd.DataFrame({\"Id\" : np.array([i for i in range(len(res))]), \"Predicted\" : np.array(res), \"Target\": np.array(targetRes)})\n",
        "        else:\n",
        "            for batch_idx, (data, dataLens) in enumerate(data_loader):\n",
        "                data, dataLens = data.to(DEVICE), dataLens.to(DEVICE)\n",
        "                predictions = model(data, dataLens, 30, batch_idx, text_input=None, isTrain=False)\n",
        "                predText = transform_index_to_letter(predictions.argmax(-1).detach().cpu().numpy())\n",
        "                res.extend(predText)\n",
        "            df = pd.DataFrame({\"Id\": np.array([i for i in range(len(res))]), \"Predicted\": np.array(res)})\n",
        "\n",
        "        df.to_csv(csv_path, index=False)  # 输出csv\n",
        "        return df"
      ],
      "metadata": {
        "id": "3ORog16mPJnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# 预测验证集\n",
        "validInfer = inference(model, dev_loader, DEV_PRED_CSV_PATH, isValid=True)\n",
        "\n",
        "# 预测测试集（提交kaggle）\n",
        "testInfer = inference(model, test_loader, TEST_PRED_CSV_PATH, isValid=False)"
      ],
      "metadata": {
        "id": "rRG4AXP7NqOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5c08ef-11e6-47b4-f35b-7a33c50cf308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average edit distance on validation set:\t16.98463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 数据可视化"
      ],
      "metadata": {
        "id": "gCd1AdnOilEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 验证集预测结果"
      ],
      "metadata": {
        "id": "SxRzxOHUit3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validInfer"
      ],
      "metadata": {
        "id": "0vQfpyc6v7GC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e0a9ab4a-ce44-4151-ac15-5d53230f6a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id                                          Predicted  \\\n",
              "0        0  THE FEMALE PRODUCES A LITTER OF TWO TO FOUR YO...   \n",
              "1        1  NUMEROUS WORKS OF ART ARE BASED ON THE STORY O...   \n",
              "2        2  THEIR SOLUTION REQUIRES DEVELOPMENT OF THE HUM...   \n",
              "3        3  HIS MOST SIGNIFICANT SCIENTIFIC PUBLICATIONS W...   \n",
              "4        4  IN RECENT YEARS SHE HAS PRIMARILY APPEARED IN ...   \n",
              "...    ...                                                ...   \n",
              "1101  1101  DOUBLE-QUOTE I THINK IT'S GRATE COMMA DOUBLE-Q...   \n",
              "1102  1102  DOUBLE-QUOTE WE WERE THINKING THERE IS AN OBSI...   \n",
              "1103  1103              AND THEY TAP IN A PERIOD DOUBLE-QUOTE   \n",
              "1104  1104  THE HOUSE SELF FAR HAS PROPOSED TO OWLOWN HYPH...   \n",
              "1105  1105  DOUBLE-QUOTE HAVING WE AREN'T OVERBOARD AND AS...   \n",
              "\n",
              "                                                 Target  \n",
              "0     THE FEMALE PRODUCES A LITTER OF TWO TO FOUR YO...  \n",
              "1     NUMEROUS WORKS OF ART ARE BASED ON THE STORY O...  \n",
              "2     THEIR SOLUTION REQUIRES DEVELOPMENT OF THE HUM...  \n",
              "3     HIS MOST SIGNIFICANT SCIENTIFIC PUBLICATIONS W...  \n",
              "4     IN RECENT YEARS SHE HAS PRIMARILY APPEARED IN ...  \n",
              "...                                                 ...  \n",
              "1101  DOUBLE-QUOTE I THINK IT'S GREAT COMMA DOUBLE-Q...  \n",
              "1102  DOUBLE-QUOTE WE WERE THINKING THERE WAS AN OUT...  \n",
              "1103                AND IT HAPPENED PERIOD DOUBLE-QUOTE  \n",
              "1104  THE HOUSE SO FAR HAS PROPOSED A LOAN HYPHEN GU...  \n",
              "1105  DOUBLE-QUOTE HAVEN'T WE ALREADY GONE OVERBOARD...  \n",
              "\n",
              "[1106 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e1a0948-5aa7-4106-8468-65d4e36df0ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>THE FEMALE PRODUCES A LITTER OF TWO TO FOUR YO...</td>\n",
              "      <td>THE FEMALE PRODUCES A LITTER OF TWO TO FOUR YO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NUMEROUS WORKS OF ART ARE BASED ON THE STORY O...</td>\n",
              "      <td>NUMEROUS WORKS OF ART ARE BASED ON THE STORY O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>THEIR SOLUTION REQUIRES DEVELOPMENT OF THE HUM...</td>\n",
              "      <td>THEIR SOLUTION REQUIRES DEVELOPMENT OF THE HUM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>HIS MOST SIGNIFICANT SCIENTIFIC PUBLICATIONS W...</td>\n",
              "      <td>HIS MOST SIGNIFICANT SCIENTIFIC PUBLICATIONS W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>IN RECENT YEARS SHE HAS PRIMARILY APPEARED IN ...</td>\n",
              "      <td>IN RECENT YEARS SHE HAS PRIMARILY APPEARED IN ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1101</th>\n",
              "      <td>1101</td>\n",
              "      <td>DOUBLE-QUOTE I THINK IT'S GRATE COMMA DOUBLE-Q...</td>\n",
              "      <td>DOUBLE-QUOTE I THINK IT'S GREAT COMMA DOUBLE-Q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1102</th>\n",
              "      <td>1102</td>\n",
              "      <td>DOUBLE-QUOTE WE WERE THINKING THERE IS AN OBSI...</td>\n",
              "      <td>DOUBLE-QUOTE WE WERE THINKING THERE WAS AN OUT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1103</th>\n",
              "      <td>1103</td>\n",
              "      <td>AND THEY TAP IN A PERIOD DOUBLE-QUOTE</td>\n",
              "      <td>AND IT HAPPENED PERIOD DOUBLE-QUOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1104</th>\n",
              "      <td>1104</td>\n",
              "      <td>THE HOUSE SELF FAR HAS PROPOSED TO OWLOWN HYPH...</td>\n",
              "      <td>THE HOUSE SO FAR HAS PROPOSED A LOAN HYPHEN GU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1105</th>\n",
              "      <td>1105</td>\n",
              "      <td>DOUBLE-QUOTE HAVING WE AREN'T OVERBOARD AND AS...</td>\n",
              "      <td>DOUBLE-QUOTE HAVEN'T WE ALREADY GONE OVERBOARD...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1106 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e1a0948-5aa7-4106-8468-65d4e36df0ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e1a0948-5aa7-4106-8468-65d4e36df0ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e1a0948-5aa7-4106-8468-65d4e36df0ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 训练集损失"
      ],
      "metadata": {
        "id": "NLeoNHGUi0H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_plot = pd.DataFrame({\"loss\":train_loss_list, \"epoch\":[i+1 for i in range(NUM_EPOCHS)]})\n",
        "\n",
        "g = sns.lineplot(x = \"epoch\", y = \"loss\", data=train_loss_plot)\n",
        "g.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "g.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
        "plt.savefig(\"./train_loss1.png\")\n",
        "os.system('mv ./train_loss1.png ./drive/MyDrive/')"
      ],
      "metadata": {
        "id": "jwbcmbvPPmE_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "1f71ab63-bf90-43db-f548-23860ab8d192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 验证集损失\n",
        "验证集损失函数：编辑距离"
      ],
      "metadata": {
        "id": "blVrxW8Ci41V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_plot = pd.DataFrame({\"editDist\":val_loss_list, \"epoch\":[i+1 for i in range(NUM_EPOCHS)]})\n",
        "\n",
        "gg = sns.lineplot(x = \"epoch\", y = \"editDist\", data=val_loss_plot)\n",
        "gg.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "gg.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
        "plt.savefig(\"./val_loss1.png\")\n",
        "os.system('mv ./val_loss1.png ./drive/MyDrive/')"
      ],
      "metadata": {
        "id": "-rqTQWUPCJuG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "211c7ea2-f930-4ac8-b7f9-79ab03bcf841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RWT2bwTVukq",
        "outputId": "5c2d7582-5521-4242-cf4f-13712c9ddf30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9199213060605742,\n",
              " 1.467084334802258,\n",
              " 1.3439937977827796,\n",
              " 1.2479048249641438,\n",
              " 1.1958052400470705,\n",
              " 1.161692036984811,\n",
              " 1.115532400996186,\n",
              " 1.0969257379379076,\n",
              " 1.0744996201776411,\n",
              " 1.0521430051295948,\n",
              " 1.021010059872955,\n",
              " 0.9421058187805097,\n",
              " 0.7778306612672732,\n",
              " 0.5689669388517237,\n",
              " 0.4324039070643196,\n",
              " 0.3517173083561643,\n",
              " 0.30992693221076206,\n",
              " 0.27797908772947866,\n",
              " 0.25170066386692286,\n",
              " 0.22442696337860069,\n",
              " 0.21211441392584365,\n",
              " 0.1974749419578286,\n",
              " 0.18185141253301956,\n",
              " 0.17692960739058733,\n",
              " 0.1582444549684993,\n",
              " 0.17329198655308986,\n",
              " 0.1467479129516801,\n",
              " 0.13659741257820326,\n",
              " 0.1229156311168227,\n",
              " 0.10457540091695096]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQN8BNOvVxYR",
        "outputId": "fe4fab6a-90fb-4b29-983c-e5694b69bccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[73.623869801085,\n",
              " 84.14376130198914,\n",
              " 109.56781193490055,\n",
              " 72.20524412296564,\n",
              " 73.57685352622062,\n",
              " 72.89602169981917,\n",
              " 69.21428571428571,\n",
              " 72.61030741410488,\n",
              " 62.35171790235081,\n",
              " 65.5994575045208,\n",
              " 63.721518987341774,\n",
              " 71.73236889692586,\n",
              " 56.831826401446655,\n",
              " 44.09493670886076,\n",
              " 33.315551537070526,\n",
              " 29.529837251356238,\n",
              " 26.707956600361662,\n",
              " 25.765822784810126,\n",
              " 23.966546112115733,\n",
              " 24.01627486437613,\n",
              " 22.305605786618443,\n",
              " 20.522603978300182,\n",
              " 20.423146473779386,\n",
              " 17.950271247739604,\n",
              " 20.820976491862567,\n",
              " 21.425858951175407,\n",
              " 16.78481012658228,\n",
              " 16.93399638336347,\n",
              " 17.329113924050635,\n",
              " 16.984629294755877]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}
